---
title: "DAM AT1 Part A Linear Regression, by Alex Brooks"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#note to self: correct working directory is setwd("/Users/alex/Projects/DAMAssignment1")
#load libraries 
library(modelr)
library(readr)
library(ggplot2)
library(dplyr)
```

### AT1 Spring 2018: Part A
### Data Cleaning and Exploratory Data Analysis 
```{r}
#import dataset 
transactions = read.csv("transactions.csv", header = T)
#check data structures match the supplied data dictionary
str(transactions)
```

## 1. a. Cleaning the data

The values in the date column should be Date format, not Factor, and customer_id needs to be String or Character, not Factor.  

```{r}
#Clean data columns to match data dictionary
transactions$date = as.Date(transactions$date, format = "%d/%m/%y")
transactions$customer_id = as.character(transactions$customer_id, format = "")
#View the data and its structure structure to confirm
str(transactions)
View(transactions)
```

##EDA: histograms of industry & location variables

```{r}
par(mfrow=c(1,2))
hist(transactions$industry, main = "Number of transactions by Industry", xlab="Industry", ylab="Number of transactions", xlim = c(0,10), ylim=c(0,50000), las=0)
hist(transactions$location, main = "Number of transactions by Location", xlab="Location", ylab="Number of transactions", xlim = c(0,10), ylim=c(0,50000), las=0)
```
## What's the EDA revealing?
It looks like locations one and two account for the greatest majority or volume of monthly transactions and there's something about industry code 6 that's very distinct from the other industry categories. 
##CHECK WITH SCRIVEN: is it accurate to say the distribution of industry and location is a poisson distribution, thus hinting at using a log linear model?

```{r}
#let's visualise a scatterplot showing industry and location variables against monthly amount
ggplot(transactions, aes(x=date, y=monthly_amount, color=industry)) + 
  geom_point() + geom_smooth()  
```

## Let's explore higher than average sales values
```{r}
#Mutate the dataset to create a new column called 'monthly_amount_above_mean' to explore higher value monthly amounts
transactions <- transactions %>%
  # creating a new variable to classify transaction column
  mutate(monthly_amount_above_mean = ifelse(monthly_amount > mean(monthly_amount), TRUE, FALSE))
# plot a bar chart by monthly amounts by date  
qplot(x = date, fill = monthly_amount_above_mean, data = transactions, geom = "bar", main = "Number of transactions by month, showing proportion above the mean")
```

This reveals most monthly amounts are below the mean and the monthly amounts grow steadily rather than steeply. Let's now look at it by industry and location, too

```{r}
# plot a bar chart by monthly amounts by location
qplot(x = location, fill = monthly_amount_above_mean, data = transactions, geom = "bar", main = "Number of transactions by location, showing proportion above the mean")
```
#So what about by industry?

```{r}
# plot a bar chart by monthly amounts by industry
qplot(x = industry, fill = monthly_amount_above_mean, data = transactions, geom = "bar", main = "Number of transactions by industry, showing proportion above the mean")
```
#1. b. Description of 2 insights from EDA
##Some insights for the sales manager
Location 1 and 2 have the highest volumes of monthly_amounts, as well as the most above-average monthly amounts.

Industry 6 has the least amount of sales transactions but though it is a low volume industry, it has above average sales amounts. 

Industries 3, 5 and 9 look to have a greater proportion of their transactions above the mean average monthly amount

### Basic model fitting
## 2. a. Creating the model
# i. Let's aggregate the data and see if we can get more insights
```{r}
# Aggregate the data, grouping by date, industry and location, and calculating the mean monthly_amount
aggregated_transactions <- transactions %>%
  group_by(date, industry, location) %>%
  summarize(monthly_amount = mean(monthly_amount, na.rm = TRUE))

# Let's also create a column for the month number and another one for year number
aggregated_transactions <- aggregated_transactions %>%
  mutate(month_number = format(as.Date(date), "%m")) %>%
  mutate(year_number = format(as.Date(date), "%Y"))

aggregated_transactions$month_number <- as.integer(aggregated_transactions$month_number)
aggregated_transactions$year_number <- as.integer(aggregated_transactions$year_number)

#transform(aggregated_transactions, month_number = as.integer(month_number), year_number = as.integer(year_number))

# View the data
aggregated_transactions
```
## 2. a. ii. Create a line plot of the variable monthly_amount for industry = 1 and location = 1
```{r}
#Create a line plot of the variable monthly_amount, for industry = 1 and location = 1

ggplot(data=filter(aggregated_transactions, industry == 1 & location == 1), aes(x=date, y=monthly_amount, group=1)) + geom_line(color="red") + geom_point() + labs(title="Line plot of mean monthly amount for Industry 1 and Location 1", x="Date", y="Mean Monthly Amount")
```
##2. a. iii) i) Trying to train the linear regression model with monthly_amount as the target
```{r}
#Monthly_amount (or more specifically mean monthly amount) is the target variable whose values are to be modeled/predicted by other variables. Can't use location or industry as a predictor variable, so only possible predictors is month number and/or date.
dataSet <- filter(aggregated_transactions, industry == 1 & location == 1)
#take a look at the filtered dataSet
str(dataSet)

# Run linear model with testing and training sets, with monthly_amount as target and month number as the predictor
#Training set is every month other than month 12
trainingSet <- filter(dataSet, month_number != "12")
#Testing set is data from month 12 only
testingSet <- filter(dataSet, month_number == "12")
```
Now for the tests of each one  
## Monthly_amount~month_number

```{r}
month_number.lm <- lm(monthly_amount~month_number, data=trainingSet)
  # plot the regression diagnostics.  Note the red line on two left plots is not straight
summary(month_number.lm)
```
The summary statistics let us see the size and significance of the fit for this model. It's unlikely to be significant or a good fit, as the months 1 through to 11 are highly variable. 

The low p-value of .01097 reflects this. The Adjusted R-Squared of 0.124 further echoes this observation.

Residuals represent a lack of fit of a line to a model - which can be seen as the model's error - and you can see the minimum to maximum residuals range from -25864 to 29675.

```{r}
# let's try to see how linear the relationship between monthly amount and month number really is - or isn't
ggplot(data = trainingSet, mapping = aes(x = month_number, y = monthly_amount)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") + labs(title="Is there a linear relationship between monthly amount and month number", x="Month Number", y="Monthly Amount")
```
## Now that's a pretty poor fit, with only two observations close to the line.
If we plot month_number to get an even better view of the sign, size and significance of the fit, we can further confirm that month number is not likely to be a good predictor of monthly sales amounts.

```{r}
# these diagnostic plots
plot(month_number.lm)
```
## Monthly Amount ~ Date 
# Now let's run a different linear model with monthly_amount as target and date as the predictor
```{r}
date.lm <- lm(monthly_amount~date, data=trainingSet)
  # plot the regression diagnostics to assess this fit versus previous model
summary(date.lm)
```
## Examining this model compared to previous model
The higher p-value of 3.423e-09 and Adjusted R-squared of 0.5584 indicates the date variable is a better predictor of monthly_amount on the Month 1 to Month 11 training data, compared to the previous model of monthly_amount to month_number.

```{r}
# let's try to see if there is a better linear relationship between monthly amount and date
ggplot(data = trainingSet, mapping = aes(x = date, y = monthly_amount)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") + labs(title="Is there a linear relationship between monthly amount and date? ", x="Date", y="Monthly Amount")
```

```{r}
#the diagnostic plots reveal this model to have more a more significant fit than the previous model of monthly_amount and month_number.
plot(date.lm)
```
## Let's see if adding month number AND date work better in tandem
# Run linear model with monthly_amount as target and month number + date as the predictor
```{r}
month_number_and_date.lm <- lm(monthly_amount~month_number + date, data=trainingSet)
  # plot the regression diagnostics.  Note the red line on two left plots is not straight
summary(month_number_and_date.lm)
```
##The model has improved slightly
The p value of 3.374e-09 is up on the monthly_amount~date model p value of 3.423e-09 and is significantly better than the monthly_amount~month_number model p value of 0.01097.

The Adjusted R-squared of 0.595 is higher with this third model than the previous two models, showing it's our best training model yet of what we've tried.

```{r}
#let's try a 3d plot of this model to check its fit
library(plotly)
#fit model, month_number_and_date.lm, and predict over sensible grid of values
date <- unique(trainingSet$date)
month_number <- unique(trainingSet$month_number)
grid <- with(trainingSet, expand.grid(date, month_number))
d <- setNames(data.frame(grid), c("date", "month_number"))
vals <- predict(month_number_and_date.lm, newdata = d)
# form matrix and give to plotly
m <- matrix(vals, nrow = length(unique(d$date)), ncol = length(unique(d$month_number)))
plot_ly() %>% add_surface(x = ~month_number, y = ~date, z = ~m)
oneplane <- expand.grid(x = 1:6, y = 1:6)
oneplane$z <- 1:6
oneplane.m <- as.matrix(spread(oneplane, key = x, value = z)[, -1])
plot_ly() %>% add_trace(x = 1:6, 
                        y = 1:6, 
                        z = oneplane.m, 
                        type = "surface", 
                        opacity = .5,
                        cauto = FALSE,
                        cmax = 1,
                        cmin = 0,
                        colorscale = list(c(0,'#d1d1d1'),c(1,'#000000')))
```

# Plot month_number + date
```{r}
plot(month_number_and_date.lm)
```

##2. a. iii) ii) How to split test and train sets
Alex to write about how it was done in this model

##2. a. iv) Create a prediction for monthly_amount in December 2016
let me work this out

##SCRIVEN QUESTION: do we need to somehow de-trend the data? Or can we 'smooth it' - if we can smooth it, how do we do that?
The yearly cycle of monthly_amounts being higher in Jan and Feb, but lower by Nov and December makes this model harder to pick and fit.

##2. b. Describe the model
## 2. b. i) How well does the model fit the data it is trained on in a statistical sense
Alex to describe and define an appropriate quantative measure and justify it
 
   ##Monthly Amount ~ Month Number
   
   Variable | Coefficient | Standard   | t -      | p-value | Adjusted  | F - 
            |             | Error      | statistic|         | R-squared | Statistic
   ---------|-------------|------------|----------|---------|------------------------
   Monthly  | 157201      |4491        |35        |0.01097  |
   Amount   |             |            |          |         |
```{r}
#TO DO
```
## 2. b. ii) How well does the model predict out of sample
Alex to define and describe an appropriate quantitative measure and justify the choice of measure
```{r}
#TO DO
```
## 2. b. iii) Which features did you end up using in your final model?
Alex to justify choice of features, and thus feature selection method
```{r}
#TO DO
```
## 3. Advanced model fitting
Describe what that means
## 3. a. Apply the modelling process you built for industry 1 and location 1 to all industries and locations programmatically
Describe what that means
```{r}
#TO DO
```
## 3. a. Apply the modelling process you built for industry 1 and location 1 to all industries and locations programmatically
Describe what that means
```{r}
#Monthly_amount (or more specifically mean monthly amount) is the target variable whose values are to be modeled/predicted by other variables. Can't use location or industry as a predictor variable, so only possible predictors is month number and/or date.

get_prediction_delta <- function(df, current_industry, current_location) {
  
  dataSet <- filter(df, industry == current_industry & location == current_location)
  # Run linear model with testing and training sets, with monthly_amount as target and month number as the predictor
  
  #Training set is every month other than month 12
  trainingSet <- filter(dataSet, month_number != "12")
  #Testing set is data from month 12 only
  testingSet <- filter(dataSet, month_number == "12")
  
  if (all(is.na(trainingSet$monthly_amount)) || all(is.na(trainingSet$month_number)) || all(is.na(trainingSet$date))) {
    delta <- "No prediction available"
  } else {
    current.lm <- lm(monthly_amount~month_number + date, data=trainingSet)
    prediction <- predict(current.lm, testingSet)
    delta <- prediction - testingSet$monthly_amount
  }
  return(delta)
}

industries <- sort(unique(transactions$industry))
locations <- sort(unique(transactions$location))

for(i in 1:length(industries)) {
  for(j in 1:length(locations)) {
    print(paste("Prediction for industry", industries[i],"and location",locations[j]))
    print("========================================")
    current_prediction_delta <- get_prediction_delta(aggregated_transactions, industries[i], locations[j])
    print(current_prediction_delta)
    print("========================================")
  }
}

#current.lm

```
## 3. b. Calculate your evaluation measure for teh training data and your testing data for all models
Describe what that means
## 3. b. Identify the two worst industries and two locations for which your method performs worst.
Describe what that means
## 4. Reporting
Describe what that means
## 4. a. Report for sales manager following CRISP-DM methodology
Describe what that means by making sure there is enough technical detail to withstand QA and technical scrutiny while explaining it for a business audience
## 4. b. APPENDIX
Put your predictions for December 2016 as an appendix - and reference predictions, the actual and the difference in your CRISP-DM Report
## REFERENCES