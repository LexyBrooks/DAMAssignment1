---
title: "DAM AT1 Part A Linear Regression, by Alex Brooks"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#note to self: correct working directory is setwd("/Users/alex/Projects/DAMAssignment1")
#load libraries 
library(modelr)
library(readr)
library(ggplot2)
library(dplyr)
```

### AT1 Spring 2018: Part A
## Data Cleaning and Exploratory Data Analysis on "transactions.csv" dataset
Read in the data check the structure to see if it needs cleaning.
```{r}
#import dataset 
transactions = read.csv("transactions.csv", header = T)
#check data structures match the supplied data dictionary
str(transactions)
#need to change date from 'Factor' to Date format to clean the data
```

## 1. a. Cleaning the data

The values in the date column should be Date format, not Factor, and customer_id needs to be String or Character, not Factor.  

```{r}
#Clean data columns into an understandable format which matches the data dictionary
transactions$date = as.Date(transactions$date, format = "%d/%m/%y")
transactions$customer_id = as.character(transactions$customer_id, format = "")
#View the data structure and eyeball the data file to confirm
str(transactions)
View(transactions)
```
##EDA: create histograms of industry and location variables
```{r}
par(mfrow=c(1,2))
hist(transactions$industry, main = "Histogram of number of transactions by Industry", xlab="Industry", ylab="Number of transactions", xlim = c(0,10), ylim=c(0,50000), las=0)
hist(transactions$location, main = "Histogram of number of transactions by Location", xlab="Location", ylab="Number of transactions", xlim = c(0,10), ylim=c(0,50000), las=0)
```
# What's the EDA revealing?
It looks like locations one and two account for the greatest majority or volume of monthly transactions and there's something about industry code 6 that's very distinct from the other industry categories.

```{r}
#let's visualise a scatterplot 
ggplot(transactions, aes(x=industry, y=monthly_amount, color=location)) + 
  geom_point() + geom_smooth()
```

```{r}
# Let's mutate the dataset to create a new column called 'monthly_amount_above_mean' to explore higher value monthly amounts
transactions <- transactions %>%
  # creating a new variable to classify transaction column
  mutate(monthly_amount_above_mean = ifelse(monthly_amount > mean(monthly_amount), TRUE, FALSE))
```

```{r}
# plot a bar chart by monthly amounts by date (DATE IS SHOWING NA, SO IT CAN'T PLOT IT)
qplot(x = date, fill = monthly_amount_above_mean, data = transactions, geom = "bar", main = "Number of transactions by month, showing proportion above the mean")
```

This reveals most monthly amounts are below the mean and the monthly amounts grow steadily rather than steeply. Let's now look at it by industry and location, too


```{r}
# plot a bar chart by monthly amounts by location
qplot(x = location, fill = monthly_amount_above_mean, data = transactions, geom = "bar", main = "Number of transactions by location, showing proportion above the mean")
```
#So what about by industry?

```{r}
# plot a bar chart by monthly amounts by industry
qplot(x = industry, fill = monthly_amount_above_mean, data = transactions, geom = "bar", main = "Number of transactions by industry, showing proportion above the mean")
```
#1. b. Description of 2 insights just from EDA
##Some insights for the sales manager
Location 1 and 2 have the highest volumes of monthly_amounts, as well as the most above-average monthly amounts.

Industry 6 has the least amount of monthly_amounts, which is likely to be sales volume data or something similar. So while industry 6 is a low volume industry, they have above average sales amounts. 

Industries 3, 5 and 9 look to have a greater proportion of their transactions above the mean average monthly amount

### Basic model fitting
## 2. a. Creating the model
# i. Let's aggregate the data and see if we can get more insights
```{r}
# Aggregate the data, grouping by date, industry and location, and calculating the mean monthly_amount
aggregated_transactions <- transactions %>%
  group_by(date, industry, location) %>%
  summarize(monthly_amount = mean(monthly_amount, na.rm = TRUE))

# Let's also create a column for the month number and another one for year number
aggregated_transactions <- aggregated_transactions %>%
  mutate(month_number = format(as.Date(date), "%m")) %>%
  mutate(year_number = format(as.Date(date), "%Y"))

aggregated_transactions$month_number <- as.integer(aggregated_transactions$month_number)
aggregated_transactions$year_number <- as.integer(aggregated_transactions$year_number)

#transform(aggregated_transactions, month_number = as.integer(month_number), year_number = as.integer(year_number))

# View the data
aggregated_transactions
```
## 2. a. ii. Create a line plot of the variable monthly_amount for industry = 1 and location = 1
```{r}
#Create a line plot of the variable monthly_amount, for industry = 1 and location = 1

ggplot(data=filter(aggregated_transactions, industry == 1 & location == 1), aes(x=date, y=monthly_amount, group=1)) + geom_line(color="red") + geom_point() + labs(title="Line plot of mean monthly amount for Industry = 1 and Location = 1", x="Date", y="Mean Monthly Amount")
```
##2. a. iii) i) Trying to train the linear regression model with monthly_amount as the target
```{r}
#Monthly_amount (or more specifically mean monthly amount) is the target variable whose values are to be modeled/predicted by other variables. Can't use location or industry as a predictor variable, so by deduction the only possible predictors is month number and/or date.
dataSet <- filter(aggregated_transactions, industry == 1 & location == 1)
#take a look at the filtered dataSet
str(dataSet)

# Create a function to compute the lm based on a specific data frame, target and predictor. Return the linear model.
run_linear_model <- function(df, target, predictor) {
  # Train a linear regression model on all the predictors (using '.' in the formula does this)
  data.lm = lm(formula = target ~ predictor, data = dataSet)
  # Analyse the model output, take note of the p-values, F-statistic and Adjusted R-squared for comparison purposes. Ideally looks at RMSE - root mean square error - to evaluate model choice.
  return(data.lm)
}

# Run linear model with monthly_amount as target and month number as the predictor
month_number.lm <- run_linear_model(dataSet, dataSet$monthly_amount, dataSet$month_number)
  # plot the regression diagnostics.  Note the red line on two left plots is not straight
summary(month_number.lm)
plot(month_number.lm)
predictedData <- predict(month_number.lm, newdata=testingSet)
# Calculate RMSE
rmse(dataSet$monthly_amount, predictedData )

# Run linear model with monthly_amount as target and date as the predictor
date.lm <- run_linear_model(dataSet, dataSet$monthly_amount, dataSet$date)
  # plot the regression diagnostics.  Note the red line on two left plots is not straight
summary(date.lm)
plot(date.lm)

# Run linear model with monthly_amount as target and month number + date as the predictor
month_number_and_date.lm <- run_linear_model(dataSet, dataSet$monthly_amount, dataSet$month_number + dataSet$date)
  # plot the regression diagnostics.  Note the red line on two left plots is not straight
summary(month_number_and_date.lm)
plot(month_number_and_date.lm)

# Run linear model with monthly_amount as target and date + month_number as the predictor
date_and_month_number.lm <- run_linear_model(dataSet, dataSet$monthly_amount, dataSet$date + dataSet$month_number)
  # plot the regression diagnostics.  Note the red line on two left plots is not straight
summary(date_and_month_number.lm)
plot(date_and_month_number.lm)
```
##2. a. iii) ii) How to split test and train sets
```{r}
#Training set is every month other than month 12
trainingSet <- filter(dataSet, month_number != "12")
#Testing set is data from month 12 only
testingSet <- filter(dataSet, month_number == "12")
#Linear model is the monthly amount against date from the training set
trained.lm <- lm(monthly_amount~date, data=trainingSet)
trained.lm
summary(trained.lm)
#Predicting the linear model using the testing set  
prediction <- predict(trained.lm, newdata=testingSet)
#Show predicted values for the 3 monthly amounts for months with a value of 12
prediction
#the difference of the prediction against the actual monthly amounts
delta <- prediction - testingSet$monthly_amount
#see delta
delta
# Calculate RMSE
testingSet$monthly_amount
prediction
rmse(testingSet$monthly_amount, prediction)
```
##2. a. iii) ii) How to split test and train sets

```{r}
#rows <- nrow(dataSet)
#f <- 0.5
#upper_bound <- floor(f * rows)
#sampleDataSet <- dataSet[sample(rows), ]
#trainingSet <- sampleDataSet[1:upper_bound, ]
trainingSet <- filter(dataSet, month_number != "12")

#testingSet <- sampleDataSet[(upper_bound+1):rows, ]
testingSet <- filter(dataSet, month_number == "12")

length(testingSet)

plot(trainingSet$date,trainingSet$monthly_amount, main="test",
xlab="date", ylab="monthly amount")




myLM <- lm(monthly_amount ~ date, data = testingSet)
plot(trainingSet$date,trainingSet$monthly_amount)
abline(myLM)

myLinearModel

View(testingSet)
myLinearModel <- lm(monthly_amount ~ date, data = trainingSet)

myLinearModel

predictedData <- predict(myLinearModel, newdata=testingSet)

predictedData

delta <- predictedData - testingSet$monthly_amount

delta

t.test(delta, conf.level = 0.95)

plot(delta)

```
##2. a. iv) Create a prediction for monthly_amount in December 2016
```{r}
multiple_runs <- function(df,class_variable_name,train_fraction,nruns){
  
  #Purpose:
  #Builds rpart model for nrun data partitions
  
  #Return value:
  #Vector containing nrun accuracies
  
  #Arguments:
  #df: variable containing dataframe
  #class_variable_name: class name as a quoted string. e.g. "Class"
  #train_fraction: fraction of data to be assigned to training set (0<train_fraction<1)
  
  #nruns: number of data partitions
  
  #find column index of class variable
  typeColNum <- grep(class_variable_name,names(df))
  #initialize accuracy vector
  accuracies <- rep(NA,nruns)
  #set seed (can be any integer)
  set.seed(24)
  #partition data
  trainset_size <- floor(train_fraction * nrow(df))

  trainset_indices <- sample(seq_len(nrow(df)), size = trainset_size)
  trainset <- df[trainset_indices, ]
  testset <- df[-trainset_indices, ]
  
  #for (i in 1:nruns){
    #build model 
    #paste builds formula string and as.formula interprets it as an R formula
    #rpart_model <- rpart(as.formula(paste(class_variable_name,"~.")),data = trainset, method="class")
    #predict on test data
    #rpart_predict <- predict(rpart_model,testset[,-typeColNum],type="class")
    #accuracy
    #accuracies[i] <- mean(rpart_predict==testset[[class_variable_name]])
   # }
  #return(accuracies)
}
```
##2. b. Describe the model
## 2. b. i) How well does the model fit the data it is trained on in a statistical sense
Alex to describe and define an appropriate quantative measure and justify it
```{r}
#TO DO
```
## 2. b. ii) How well does the model predict out of sample
Alex to define and describe an appropriate quantitative measure and justify the choice of measure
```{r}
#TO DO
```
## 2. b. iii) Which features did you end up using in your final model?
Alex to justify choice of features, and thus feature selection method
```{r}
#TO DO
```
## 3. Advanced model fitting
Describe what that means
## 3. a. Apply the modelling process you built for industry 1 and location 1 to all industries and locations programmatically
Describe what that means
```{r}
#TO DO
```
## 3. a. Apply the modelling process you built for industry 1 and location 1 to all industries and locations programmatically
Describe what that means
```{r}
#TO DO
```
## 3. b. Calculate your evaluation measure for teh training data and your testing data for all models
Describe what that means
## 3. b. Identify the two worst industries and two locations for which your method performs worst.
Describe what that means
## 4. Reporting
Describe what that means
## 4. a. Report for sales manager following CRISP-DM methodology
Describe what that means by making sure there is enough technical detail to withstand QA and technical scrutiny while explaining it for a business audience
## 4. b. APPENDIX
Put your predictions for December 2016 as an appendix - and reference predictions, the actual and the difference in your CRISP-DM Report
## REFERENCES